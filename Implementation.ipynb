{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "consistent-trade",
   "metadata": {},
   "source": [
    "# Joshua Placidi - Free Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "armed-exemption",
   "metadata": {},
   "source": [
    "## Imports and Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "described-hunter",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext lab_black\n",
    "import pandas as pd\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "import altair as alt\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "professional-insight",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bank_transaction_id</th>\n",
       "      <th>bank_transaction_description</th>\n",
       "      <th>bank_transaction_amount</th>\n",
       "      <th>bank_transaction_type</th>\n",
       "      <th>bank_transaction_category</th>\n",
       "      <th>bank_transaction_dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21786195</td>\n",
       "      <td>citylink</td>\n",
       "      <td>-13.80</td>\n",
       "      <td>MPO</td>\n",
       "      <td>TRAVEL</td>\n",
       "      <td>TRAIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21786196</td>\n",
       "      <td>citylink</td>\n",
       "      <td>-13.14</td>\n",
       "      <td>DEB</td>\n",
       "      <td>TRAVEL</td>\n",
       "      <td>TRAIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21786197</td>\n",
       "      <td>1Jul19 OYSTER</td>\n",
       "      <td>-36.98</td>\n",
       "      <td>DEB</td>\n",
       "      <td>TRAVEL</td>\n",
       "      <td>TRAIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21786198</td>\n",
       "      <td>travelodge</td>\n",
       "      <td>-75.73</td>\n",
       "      <td>MPO</td>\n",
       "      <td>TRAVEL</td>\n",
       "      <td>TRAIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21786199</td>\n",
       "      <td>6Jul19 RINGGO</td>\n",
       "      <td>-37.86</td>\n",
       "      <td>CSH</td>\n",
       "      <td>TRAVEL</td>\n",
       "      <td>TRAIN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bank_transaction_id bank_transaction_description  bank_transaction_amount  \\\n",
       "0             21786195                     citylink                   -13.80   \n",
       "1             21786196                     citylink                   -13.14   \n",
       "2             21786197                1Jul19 OYSTER                   -36.98   \n",
       "3             21786198                   travelodge                   -75.73   \n",
       "4             21786199                6Jul19 RINGGO                   -37.86   \n",
       "\n",
       "  bank_transaction_type bank_transaction_category bank_transaction_dataset  \n",
       "0                   MPO                    TRAVEL                    TRAIN  \n",
       "1                   DEB                    TRAVEL                    TRAIN  \n",
       "2                   DEB                    TRAVEL                    TRAIN  \n",
       "3                   MPO                    TRAVEL                    TRAIN  \n",
       "4                   CSH                    TRAVEL                    TRAIN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in datasets\n",
    "features_df = pd.read_csv(\"./bank_transactions_dataset/bank_transaction_features.csv\")\n",
    "labels_df = pd.read_csv(\"./bank_transactions_dataset/bank_transaction_labels.csv\")\n",
    "\n",
    "# Combine labels and features into one df\n",
    "combined_df = pd.merge(features_df, labels_df, on=\"bank_transaction_id\")\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parental-milan",
   "metadata": {},
   "source": [
    "## Part 1: Visualising Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "restricted-mathematics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- features_df shape: (12500, 4)\n",
      "- labels_df shape: (12500, 3)\n",
      "- combined_df shape: (12500, 6)\n",
      "\n",
      "- combined_df info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 12500 entries, 0 to 12499\n",
      "Data columns (total 6 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   bank_transaction_id           12500 non-null  int64  \n",
      " 1   bank_transaction_description  12369 non-null  object \n",
      " 2   bank_transaction_amount       12500 non-null  float64\n",
      " 3   bank_transaction_type         12500 non-null  object \n",
      " 4   bank_transaction_category     12500 non-null  object \n",
      " 5   bank_transaction_dataset      12500 non-null  object \n",
      "dtypes: float64(1), int64(1), object(4)\n",
      "memory usage: 683.6+ KB\n"
     ]
    }
   ],
   "source": [
    "print(\"- features_df shape:\", features_df.shape)\n",
    "print(\"- labels_df shape:\", labels_df.shape)\n",
    "print(\"- combined_df shape:\", combined_df.shape)\n",
    "print(\"\\n- combined_df info:\")\n",
    "combined_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "headed-variety",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace null values in transaction description with empty string\n",
    "combined_df[\"bank_transaction_description\"].fillna(\"\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "average-bottle",
   "metadata": {},
   "source": [
    "- bank_transaction_description column has 131 null values. Due to this column containing string descriptions of the transactions I will fill these null cells with empty strings (\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "engaging-calendar",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a bar chart of the count distribution of transaction types\n",
    "def type_dist_graph(df):\n",
    "    chart = (\n",
    "        alt.Chart(df)\n",
    "        .mark_bar()\n",
    "        .encode(\n",
    "            x=alt.X(\"bank_transaction_type\", title=\"Count\"),\n",
    "            y=alt.Y(\"index\", title=\"Transaction Type\"),\n",
    "            color=alt.Color(\"bank_transaction_type:N\", legend=None),\n",
    "        )\n",
    "    )\n",
    "    return chart\n",
    "\n",
    "\n",
    "# Generate a bar chart of the count distribution of transaction categories\n",
    "def cat_dist_graph(df):\n",
    "    chart = (\n",
    "        alt.Chart(df)\n",
    "        .mark_bar()\n",
    "        .encode(\n",
    "            x=alt.X(\"bank_transaction_category\", title=\"Count\"),\n",
    "            y=alt.Y(\"index\", title=\"Transaction Category\"),\n",
    "            color=alt.Color(\"bank_transaction_category:N\", legend=None),\n",
    "        )\n",
    "    )\n",
    "    return chart\n",
    "\n",
    "\n",
    "# Given a df return graphs for the transaction type and category distributions\n",
    "def show_graphs(df):\n",
    "    df_type = df[\"bank_transaction_type\"].value_counts().to_frame().reset_index()\n",
    "    df_cat = df[\"bank_transaction_category\"].value_counts().to_frame().reset_index()\n",
    "    return type_dist_graph(df_type) | cat_dist_graph(df_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "built-coffee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train samples count: 10000\n",
      "val samples count 2500\n"
     ]
    }
   ],
   "source": [
    "train_df = combined_df[combined_df.bank_transaction_dataset == \"TRAIN\"]\n",
    "val_df = combined_df[combined_df.bank_transaction_dataset == \"VAL\"]\n",
    "print(\"train samples count:\", len(train_df))\n",
    "print(\"val samples count\", len(val_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amazing-cosmetic",
   "metadata": {},
   "source": [
    "- Graphically visualise dataset distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "convinced-imperial",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined data distributions ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-2811e120e35f43689e0961ea885f1042\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-2811e120e35f43689e0961ea885f1042\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-2811e120e35f43689e0961ea885f1042\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.8.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function loadScript(lib) {\n",
       "      return new Promise(function(resolve, reject) {\n",
       "        var s = document.createElement('script');\n",
       "        s.src = paths[lib];\n",
       "        s.async = true;\n",
       "        s.onload = () => resolve(paths[lib]);\n",
       "        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "        document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "      });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else if (typeof vegaEmbed === \"function\") {\n",
       "      displayChart(vegaEmbed);\n",
       "    } else {\n",
       "      loadScript(\"vega\")\n",
       "        .then(() => loadScript(\"vega-lite\"))\n",
       "        .then(() => loadScript(\"vega-embed\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"hconcat\": [{\"data\": {\"name\": \"data-25ac36a31a582b1b48180bbbc4780290\"}, \"mark\": \"bar\", \"encoding\": {\"color\": {\"type\": \"nominal\", \"field\": \"bank_transaction_type\", \"legend\": null}, \"x\": {\"type\": \"quantitative\", \"field\": \"bank_transaction_type\", \"title\": \"Count\"}, \"y\": {\"type\": \"nominal\", \"field\": \"index\", \"title\": \"Transaction Type\"}}}, {\"data\": {\"name\": \"data-207eb89b064d0a232a9c34fd0ccd694c\"}, \"mark\": \"bar\", \"encoding\": {\"color\": {\"type\": \"nominal\", \"field\": \"bank_transaction_category\", \"legend\": null}, \"x\": {\"type\": \"quantitative\", \"field\": \"bank_transaction_category\", \"title\": \"Count\"}, \"y\": {\"type\": \"nominal\", \"field\": \"index\", \"title\": \"Transaction Category\"}}}], \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.8.1.json\", \"datasets\": {\"data-25ac36a31a582b1b48180bbbc4780290\": [{\"index\": \"DEB\", \"bank_transaction_type\": 4678}, {\"index\": \"CHG\", \"bank_transaction_type\": 2510}, {\"index\": \"CSH\", \"bank_transaction_type\": 2041}, {\"index\": \"MPO\", \"bank_transaction_type\": 1484}, {\"index\": \"DD\", \"bank_transaction_type\": 1108}, {\"index\": \"FPO\", \"bank_transaction_type\": 679}], \"data-207eb89b064d0a232a9c34fd0ccd694c\": [{\"index\": \"ACCOMMODATION_AND_MEALS\", \"bank_transaction_category\": 3765}, {\"index\": \"TRAVEL\", \"bank_transaction_category\": 3166}, {\"index\": \"BANK_OR_FINANCE_CHARGES\", \"bank_transaction_category\": 2790}, {\"index\": \"MOTOR_EXPENSES\", \"bank_transaction_category\": 1609}, {\"index\": \"INSURANCE\", \"bank_transaction_category\": 1170}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.HConcatChart(...)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Combined data distributions ---\")\n",
    "show_graphs(combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "automotive-liberty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train distributions ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-967b75de1232460794762dc3e96d5c8b\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-967b75de1232460794762dc3e96d5c8b\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-967b75de1232460794762dc3e96d5c8b\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.8.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function loadScript(lib) {\n",
       "      return new Promise(function(resolve, reject) {\n",
       "        var s = document.createElement('script');\n",
       "        s.src = paths[lib];\n",
       "        s.async = true;\n",
       "        s.onload = () => resolve(paths[lib]);\n",
       "        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "        document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "      });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else if (typeof vegaEmbed === \"function\") {\n",
       "      displayChart(vegaEmbed);\n",
       "    } else {\n",
       "      loadScript(\"vega\")\n",
       "        .then(() => loadScript(\"vega-lite\"))\n",
       "        .then(() => loadScript(\"vega-embed\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"hconcat\": [{\"data\": {\"name\": \"data-30f83fd69bddb62ee17cd46de905417c\"}, \"mark\": \"bar\", \"encoding\": {\"color\": {\"type\": \"nominal\", \"field\": \"bank_transaction_type\", \"legend\": null}, \"x\": {\"type\": \"quantitative\", \"field\": \"bank_transaction_type\", \"title\": \"Count\"}, \"y\": {\"type\": \"nominal\", \"field\": \"index\", \"title\": \"Transaction Type\"}}}, {\"data\": {\"name\": \"data-734953ba7c3c0fb5923be0284b49f785\"}, \"mark\": \"bar\", \"encoding\": {\"color\": {\"type\": \"nominal\", \"field\": \"bank_transaction_category\", \"legend\": null}, \"x\": {\"type\": \"quantitative\", \"field\": \"bank_transaction_category\", \"title\": \"Count\"}, \"y\": {\"type\": \"nominal\", \"field\": \"index\", \"title\": \"Transaction Category\"}}}], \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.8.1.json\", \"datasets\": {\"data-30f83fd69bddb62ee17cd46de905417c\": [{\"index\": \"DEB\", \"bank_transaction_type\": 3717}, {\"index\": \"CHG\", \"bank_transaction_type\": 2029}, {\"index\": \"CSH\", \"bank_transaction_type\": 1660}, {\"index\": \"MPO\", \"bank_transaction_type\": 1210}, {\"index\": \"DD\", \"bank_transaction_type\": 861}, {\"index\": \"FPO\", \"bank_transaction_type\": 523}], \"data-734953ba7c3c0fb5923be0284b49f785\": [{\"index\": \"ACCOMMODATION_AND_MEALS\", \"bank_transaction_category\": 3017}, {\"index\": \"TRAVEL\", \"bank_transaction_category\": 2578}, {\"index\": \"BANK_OR_FINANCE_CHARGES\", \"bank_transaction_category\": 2250}, {\"index\": \"MOTOR_EXPENSES\", \"bank_transaction_category\": 1235}, {\"index\": \"INSURANCE\", \"bank_transaction_category\": 920}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.HConcatChart(...)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Train distributions ---\")\n",
    "show_graphs(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "approved-granny",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val distributions ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-935b994a3b4947a1979a9223608215ea\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-935b994a3b4947a1979a9223608215ea\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-935b994a3b4947a1979a9223608215ea\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.8.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function loadScript(lib) {\n",
       "      return new Promise(function(resolve, reject) {\n",
       "        var s = document.createElement('script');\n",
       "        s.src = paths[lib];\n",
       "        s.async = true;\n",
       "        s.onload = () => resolve(paths[lib]);\n",
       "        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "        document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "      });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else if (typeof vegaEmbed === \"function\") {\n",
       "      displayChart(vegaEmbed);\n",
       "    } else {\n",
       "      loadScript(\"vega\")\n",
       "        .then(() => loadScript(\"vega-lite\"))\n",
       "        .then(() => loadScript(\"vega-embed\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"hconcat\": [{\"data\": {\"name\": \"data-c353d6882a6067e4596e9aeefe29038e\"}, \"mark\": \"bar\", \"encoding\": {\"color\": {\"type\": \"nominal\", \"field\": \"bank_transaction_type\", \"legend\": null}, \"x\": {\"type\": \"quantitative\", \"field\": \"bank_transaction_type\", \"title\": \"Count\"}, \"y\": {\"type\": \"nominal\", \"field\": \"index\", \"title\": \"Transaction Type\"}}}, {\"data\": {\"name\": \"data-f50e5d705cf14a24395546897ea76d88\"}, \"mark\": \"bar\", \"encoding\": {\"color\": {\"type\": \"nominal\", \"field\": \"bank_transaction_category\", \"legend\": null}, \"x\": {\"type\": \"quantitative\", \"field\": \"bank_transaction_category\", \"title\": \"Count\"}, \"y\": {\"type\": \"nominal\", \"field\": \"index\", \"title\": \"Transaction Category\"}}}], \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.8.1.json\", \"datasets\": {\"data-c353d6882a6067e4596e9aeefe29038e\": [{\"index\": \"DEB\", \"bank_transaction_type\": 961}, {\"index\": \"CHG\", \"bank_transaction_type\": 481}, {\"index\": \"CSH\", \"bank_transaction_type\": 381}, {\"index\": \"MPO\", \"bank_transaction_type\": 274}, {\"index\": \"DD\", \"bank_transaction_type\": 247}, {\"index\": \"FPO\", \"bank_transaction_type\": 156}], \"data-f50e5d705cf14a24395546897ea76d88\": [{\"index\": \"ACCOMMODATION_AND_MEALS\", \"bank_transaction_category\": 748}, {\"index\": \"TRAVEL\", \"bank_transaction_category\": 588}, {\"index\": \"BANK_OR_FINANCE_CHARGES\", \"bank_transaction_category\": 540}, {\"index\": \"MOTOR_EXPENSES\", \"bank_transaction_category\": 374}, {\"index\": \"INSURANCE\", \"bank_transaction_category\": 250}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.HConcatChart(...)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Val distributions ---\")\n",
    "show_graphs(val_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flexible-environment",
   "metadata": {},
   "source": [
    "- There is class inbalance in the dataset with many more training examples for *ACCOMMODATION_AND_MEALS*, *TRAVEL*, *BANK_OR_FINANCE_CHARGES* than for *MOTOR_EXPENSES* and *INSURANCE*\n",
    "- Distribution are fairly similar between train and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "engaged-speech",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combined_df transaction amount mean: -19.613016800000057\n",
      "train_df transaction amount mean: -20.073671000000086\n",
      "val_df transaction amount mean: -17.770399999999967\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"combined_df transaction amount mean:\",\n",
    "    combined_df[\"bank_transaction_amount\"].mean(),\n",
    ")\n",
    "print(\n",
    "    \"train_df transaction amount mean:\",\n",
    "    train_df[\"bank_transaction_amount\"].mean(),\n",
    ")\n",
    "print(\n",
    "    \"val_df transaction amount mean:\",\n",
    "    val_df[\"bank_transaction_amount\"].mean(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satisfactory-buying",
   "metadata": {},
   "source": [
    "- A 2.3 difference in transaction amount between train and val data, this difference is larger than I would expect for large randomly distributed data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bright-commons",
   "metadata": {},
   "source": [
    "## Part 2: Classifier\n",
    "\n",
    "I have been using BERT in a project recently to extract semantic meaning from words. The task of trying to predict categories from natural sentences immediately appeared to be an ideal task to utilise the BERT model. I have used the pretrained sequence classification BERT model and then fine tuned it for 5 epochs on the bank transaction training data. I believe the model shows good results but could definitely be improved (as detailed in the final cell of this notebook)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "suspected-procurement",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "from transformers import BertForSequenceClassification\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "device = \"cuda:0\"\n",
    "batch_size = 192"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fatal-laugh",
   "metadata": {},
   "source": [
    "- Defining a Transaction_Dataset to store and load samples from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ordinary-foundation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode category values to integers, i.e 'TRAVEL' is replace with '0'\n",
    "combined_df.bank_transaction_type = pd.factorize(combined_df.bank_transaction_type)[0]\n",
    "# True cats stores the category labels with index corresponding to integer representations, i.e true_cats[0] = 'TRAVEL'\n",
    "combined_df.bank_transaction_category, true_cats = pd.factorize(\n",
    "    combined_df.bank_transaction_category\n",
    ")\n",
    "\n",
    "# Split data into train and val\n",
    "train_df = combined_df[combined_df.bank_transaction_dataset == \"TRAIN\"]\n",
    "val_df = combined_df[combined_df.bank_transaction_dataset == \"VAL\"]\n",
    "\n",
    "\n",
    "# Define class to stored and load tranctional data\n",
    "class Transaction_Dataset(Dataset):\n",
    "    def __init__(self, transactions_df):\n",
    "        self.transactions = []\n",
    "        for _, row in transactions_df.iterrows():\n",
    "            t = {}\n",
    "\n",
    "            t[\"desc\"] = row[\"bank_transaction_description\"]\n",
    "            t[\"cat\"] = row[\"bank_transaction_category\"]\n",
    "\n",
    "            self.transactions.append(t)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.transactions)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        t = self.transactions[idx]\n",
    "\n",
    "        bert_tokens = get_bert_tokens(t[\"desc\"])\n",
    "\n",
    "        label = int(t[\"cat\"])\n",
    "        label = torch.tensor(label)\n",
    "\n",
    "        return bert_tokens.to(device), label.to(device)\n",
    "\n",
    "\n",
    "# Function takes a string and returns the generated bert tokens, padded/truncated to a max_length = 10\n",
    "def get_bert_tokens(desc):\n",
    "    tokens = torch.tensor(\n",
    "        tokenizer.encode(\n",
    "            desc, max_length=10, padding=\"max_length\", truncation=\"longest_first\"\n",
    "        )\n",
    "    )\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "administrative-corrections",
   "metadata": {},
   "source": [
    "- Get dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "constant-exhaust",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train batch count = 53\n",
      "Val batch count = 14\n"
     ]
    }
   ],
   "source": [
    "train_data = Transaction_Dataset(train_df)\n",
    "val_data = Transaction_Dataset(val_df)\n",
    "\n",
    "# Get train/val data loader randomly shuffled\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_data, batch_size=batch_size, shuffle=True, num_workers=0\n",
    ")\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_data, batch_size=batch_size, shuffle=True, num_workers=0\n",
    ")\n",
    "\n",
    "print(\"Train batch count =\", len(train_loader))\n",
    "print(\"Val batch count =\", len(val_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "illegal-matter",
   "metadata": {},
   "source": [
    "- Define some helper functions used to evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "military-evidence",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Get f1 score given predictions and their true values\n",
    "def get_f1_score(preds, labels):\n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return f1_score(labels_flat, preds_flat, average=\"weighted\")\n",
    "\n",
    "\n",
    "# Get model accuracy and accuracy per class (returned as dictionary)\n",
    "def accuracy_per_class(preds, labels):\n",
    "    correct = 0\n",
    "    acc_per_class = {}\n",
    "    for cat in true_cats:\n",
    "        acc_per_class[cat] = [0, 0]\n",
    "\n",
    "    for i in range(len(preds)):\n",
    "\n",
    "        if np.argmax(preds[i]) == labels[i]:\n",
    "            correct += 1\n",
    "            acc_per_class[true_cats[labels[i]]][0] += 1\n",
    "\n",
    "        acc_per_class[true_cats[labels[i]]][1] += 1\n",
    "    return round((correct / len(preds)) * 100, 2), acc_per_class\n",
    "\n",
    "\n",
    "# Evaluate the models performance\n",
    "def evaluate(val_loader):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    loss_val_total = 0\n",
    "    predictions, true_vals = [], []\n",
    "\n",
    "    for tokens, labels in val_loader:\n",
    "        inputs = {\"input_ids\": tokens, \"labels\": labels}\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "\n",
    "        loss = outputs[0]\n",
    "        logits = outputs[1]\n",
    "        loss_val_total += loss.item()\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = inputs[\"labels\"].cpu().numpy()\n",
    "        predictions.append(logits)\n",
    "        true_vals.append(label_ids)\n",
    "\n",
    "    loss_val_avg = loss_val_total / len(val_loader)\n",
    "\n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    true_vals = np.concatenate(true_vals, axis=0)\n",
    "\n",
    "    return loss_val_avg, predictions, true_vals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "binary-significance",
   "metadata": {},
   "source": [
    "- Get pretrained bert model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "absent-interval",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=5)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amazing-jaguar",
   "metadata": {},
   "source": [
    "- Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "stupid-deviation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00440c211ff4468ebb0004e5bd5006c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - Epoch 1\n",
      "Average train loss: 1.4\n",
      "Validation loss: 1.1\n",
      "F1 score 0.59\n",
      "\n",
      "\n",
      "  - Epoch 2\n",
      "Average train loss: 0.9\n",
      "Validation loss: 0.63\n",
      "F1 score 0.78\n",
      "\n",
      "\n",
      "  - Epoch 3\n",
      "Average train loss: 0.6\n",
      "Validation loss: 0.49\n",
      "F1 score 0.84\n",
      "\n",
      "\n",
      "  - Epoch 4\n",
      "Average train loss: 0.49\n",
      "Validation loss: 0.42\n",
      "F1 score 0.85\n",
      "\n",
      "\n",
      "  - Epoch 5\n",
      "Average train loss: 0.45\n",
      "Validation loss: 0.5\n",
      "F1 score 0.86\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fine tune model for 5 epochs\n",
    "epochs = 5\n",
    "\n",
    "# Using AdamW and linear scheduler with warmup as recommend by authors of similar projects (https://towardsdatascience.com/multi-label-multi-class-text-classification-with-bert-transformer-and-keras-c6355eccb63a, https://towardsdatascience.com/multi-class-text-classification-with-deep-learning-using-bert-b59ca2f5c613)\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5, eps=1e-8)\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer, num_warmup_steps=0, num_training_steps=len(train_loader) * epochs\n",
    ")\n",
    "\n",
    "# Typical training loop\n",
    "for epoch in tqdm(range(1, epochs + 1)):\n",
    "    print(\"  - Epoch\", epoch)\n",
    "\n",
    "    model.train()\n",
    "    loss_train_total = 0\n",
    "\n",
    "    for tokens, labels in train_loader:\n",
    "        model.zero_grad()\n",
    "\n",
    "        inputs = {\"input_ids\": tokens, \"labels\": labels}\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "        loss = outputs[0]\n",
    "        loss_train_total += loss.item()\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "    # Print epoch statistics\n",
    "    loss_train_avg = loss_train_total / len(train_loader)\n",
    "    print(\"Average train loss:\", round(loss_train_avg, 2))\n",
    "\n",
    "    val_loss, predictions, true_vals = evaluate(val_loader)\n",
    "    val_f1 = get_f1_score(predictions, true_vals)\n",
    "    print(\"Validation loss:\", round(val_loss, 2))\n",
    "    print(\"F1 score\", round(val_f1, 2))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complimentary-midnight",
   "metadata": {},
   "source": [
    " - Evaluate final model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "increased-linux",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 85.72\n",
      "F1 score: 0.8552536952633207\n",
      "\n",
      " - TRAVEL 81.12\n",
      " - MOTOR_EXPENSES 69.79\n",
      " - ACCOMMODATION_AND_MEALS 88.1\n",
      " - BANK_OR_FINANCE_CHARGES 96.11\n",
      " - INSURANCE 90.8\n"
     ]
    }
   ],
   "source": [
    "# Get val predictions\n",
    "_, predictions, true_vals = evaluate(val_loader)\n",
    "\n",
    "# Get model accuracy (acc) and accuracy per class (acc_per_class)\n",
    "acc, acc_per_class = accuracy_per_class(predictions, true_vals)\n",
    "\n",
    "# Get f1 scores\n",
    "f1 = get_f1_score(predictions, true_vals)\n",
    "\n",
    "# Print metrics\n",
    "print(\"Model Accuracy:\", acc)\n",
    "print(\"F1 score:\", f1)\n",
    "print()\n",
    "\n",
    "for key, val in acc_per_class.items():\n",
    "    class_acc = round((val[0] / val[1]) * 100, 2)\n",
    "    print(\" - \" + key, class_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "considerable-graphic",
   "metadata": {},
   "source": [
    "### Test some sample transaction descriptions for fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "maritime-mainstream",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(desc):\n",
    "    tokens = get_bert_tokens(desc)\n",
    "\n",
    "    desc_tensor = torch.Tensor(1, 10).long().to(device)\n",
    "    desc_tensor[0] = tokens\n",
    "\n",
    "    model_in = {\"input_ids\": desc_tensor}\n",
    "    output = model(**model_in)\n",
    "\n",
    "    return true_cats[torch.argmax(output[0]).item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "documented-tourism",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TRAVEL'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_prediction(\"motorway toll bridge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dental-lodge",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ACCOMMODATION_AND_MEALS'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_prediction(\"a very large coffee order\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "hollywood-information",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'INSURANCE'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_prediction(\"money to cover dental operation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "processed-death",
   "metadata": {},
   "source": [
    "## Model improvements\n",
    "\n",
    "The first step I would take to improve the model is to utilise the other features availible for transactions. Then fine tuning of the model hyperparameters (epochs, lr, scheduler...) should help extract slightly better performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
